[
  {
    "objectID": "importing.html",
    "href": "importing.html",
    "title": "Importing additional spatial data",
    "section": "",
    "text": "library(sf)\nlibrary(mapview)"
  },
  {
    "objectID": "importing.html#mined-units",
    "href": "importing.html#mined-units",
    "title": "Importing additional spatial data",
    "section": "Mined Units",
    "text": "Mined Units\nThe mined units can be read in directly with st_read.\n\nmined <- st_read('https://ca.dep.state.fl.us/arcgis/rest/services/OpenData/MMP_MINEDUNITS/MapServer/0/query?outFields=*&where=1%3D1&f=geojson')\n\nReading layer `OGRGeoJSON' from data source \n  `https://ca.dep.state.fl.us/arcgis/rest/services/OpenData/MMP_MINEDUNITS/MapServer/0/query?outFields=*&where=1%3D1&f=geojson' \n  using driver `GeoJSON'\nSimple feature collection with 371 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -82.95369 ymin: 27.46063 xmax: -81.69582 ymax: 30.51925\nGeodetic CRS:  WGS 84\n\nmapview(mined)"
  },
  {
    "objectID": "importing.html#brownfield-sites",
    "href": "importing.html#brownfield-sites",
    "title": "Importing additional spatial data",
    "section": "Brownfield sites",
    "text": "Brownfield sites\nDownload the zipped kml file to a temporary directory.\n\n# url with zipped kml\nurlin <- 'https://ordsext.epa.gov/FLA/www3/acres_frs.kmz'\n\n# download file\ntmp1 <- tempfile(fileext = \".kmz\")\ndownload.file(url = urlin, destfile = tmp1, method = 'curl')\n\nUnzip the kmz file.\n\ntmp2 <- tempdir()\nunzip(tmp1, exdir = tmp2)\n\nGet the name of the kml file to read.\n\nlyr <- unzip(tmp1, list = T)$Name\nfl <- paste(c(tmp2, lyr), collapse = \"\\\\\")\nfl <- gsub('\\\\\\\\', '/', fl)\n\nRead the kml file with st_read and drop Z dimension with st_zm. Here, the Tampa sites are loaded. You can view all possible locations in the kml file with st_layers.\n\ndat <- st_read(fl, layer = 'TAMPA') %>% \n  st_zm()\n\nReading layer `TAMPA' from data source `/tmp/RtmpkL00Ps/ACRES_FRS.KML' using driver `LIBKML'\nSimple feature collection with 103 features and 12 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: -82.51857 ymin: 27.87108 xmax: -82.3533 ymax: 28.07826\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nmapview(dat)\n\n\n\n\n\n\nUnlink the temporary files to delete them when you are finished.\n\nunlink(tmp1, recursive = TRUE)\nunlink(fl, recursive = TRUE)"
  },
  {
    "objectID": "importing.html#another-dataset",
    "href": "importing.html#another-dataset",
    "title": "Importing additional spatial data",
    "section": "Another dataset",
    "text": "Another dataset\nNot sure what this one is… but process is similar except two zip files have to be unzipped.\nDownload zip file to temp directory and unzip to temp directory.\n\nurlin <- 'https://static-data-screeningtool.geoplatform.gov/data-versions/1.0/data/score/downloadable/1.0-shapefile-codebook.zip'\n\ntmp1 <- tempfile(fileext = \".zip\")\ndownload.file(url = urlin, destfile = tmp1)\n\ntmp2 <- tempdir()\nunzip(tmp1, exdir = tmp2)\n\nUnzip usa.zip file.\n\nzip1 <- list.files(tmp2, 'usa\\\\.zip', full.names = T)\nunzip(zip1, exdir = tmp2)\n\nGet file path for usa.shp, import with sf.\n\nfl <- list.files(tmp2, '\\\\.shp', full.names = T)\ndat <- st_read(fl)\n\nReading layer `usa' from data source `/tmp/RtmpkL00Ps/usa.shp' using driver `ESRI Shapefile'\nSimple feature collection with 74134 features and 123 fields (with 367 geometries empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.2311 ymin: -14.60181 xmax: 179.8597 ymax: 71.44106\nGeodetic CRS:  WGS 84\n\n\nClip to Tampa Bay watershed boundaries. CRS is the same, so no need to transform.\n\nload(file = 'data/tbshed.RData')\n\ndattb2 <- dat %>% \n  st_intersection(tbshed)\n\nsave(dattb2, file = 'data/dattb2.RData')\n\nView the data.\n\nmapview(dattb2)\n\n\n\n\n\n\nRemove temporary files.\n\nunlink(tmp1, recursive = TRUE)\nunlink(zip1)\nfls <- list.files(tmp2, gsub('\\\\.shp$', '', basename(fl)), full.names = T)\nfile.remove(fls)\n\n[1] TRUE TRUE TRUE TRUE TRUE"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Getting EJScreen data",
    "section": "",
    "text": "The Tampa Bay Estuary Program (TBEP) is developing a methodology as part of its new Equity Strategy to identify historically underserved (i.e., disadvantaged) communities across the Tampa Bay watershed to support the goals of the White House’s Justice40 Initiative (EO 14008) and the Environmental Protection Agency’s Equity Action Plan (EO 13985). The purpose of this initiative is to ensure TBEP delivers equitable and fair access to the benefits from environmental programs for all communities.\nBelow, we have provided instructions for downloading the data that will be used to identify underserved communities in Tampa Bay. To view instructions for cleaning the data and utilizing the demographic indices to map underserved communities, see Mapping underserved communities.\nThe method described below is presented in R coding language, but users who prefer working with GIS software (e.g., ArcGIS or QGIS) should also be able to reproduce the maps by following along in the descriptions of each step.\nLoad the required R packages (install first as needed).\n\nlibrary(sf)\nlibrary(mapview)\n\nTo collect demographic data that will be used for identifying underserved communities, we will be downloading U.S. census data provided by the EPA’s 2022 Environmental Justice Screening Tool (EJScreen). This data is available from https://gaftp.epa.gov/EJSCREEN/2022/. Here you will find different versions of EJScreen data that are summarized, calculated, and visualized in different ways to meet your particular needs (e.g., census blocks or tracts, state or national percentiles, tabular or spatial data).\nIn our case, we are interested in obtaining spatial data for the supplemental demographic indices, summarized at the census tract level, using national percentiles as our thresholds for identifying underserved communities. The appropriate file to download for our requirements is “EJSCREEN_2022_Supplemental_with_AS_CNMI_GU_VI_Tracts.gdb.zip”. However, you may want to explore the files available to see if a different file is more appropriate based on your needs.\nDownload the relevant file from EJScreen. The file is downloaded to a temporary directory.\n\n# url with zip gdb to download\nurlin <- 'https://gaftp.epa.gov/EJSCREEN/2022/EJSCREEN_2022_Supplemental_with_AS_CNMI_GU_VI_Tracts.gdb.zip'\n\n# download file\ntmp1 <- tempfile(fileext = \".zip\")\ndownload.file(url = urlin, destfile = tmp1)\n\nUnzip the geodatabase that was downloaded to a second temporary directory.\n\n# unzip file\ntmp2 <- tempdir()\nutils::unzip(tmp1, exdir = tmp2)\n\nRead the polygon layer from the geodatabase.\n\n# get the layers from the gdb\ngdbpth <- list.files(tmp2, pattern = '\\\\.gdb$', full.names = T)\ngdbpth <- gsub('\\\\\\\\', '/', gdbpth)\nlyr <- st_layers(gdbpth)$name\n\n# read the layer\ndat <- st_read(dsn = gdbpth, lyr)\n\nTo exclude census tracts outside of our watershed boundary, intersect the layer with the Tampa Bay watershed. If working in a different area, you will want to replace the tbshed shapefile with your own boundary file.\n\nload(file = 'data/tbshed.RData')\n\n# intersect the layer with the tb watershed\ndattb <- dat %>% \n  st_transform(crs = st_crs(tbshed)) %>% \n  st_make_valid() %>% \n  st_intersection(tbshed)\n\nView the data using mapview. You can see that we now have the desired spatial data just for our watershed.\n\n\n\n\nmapview(dattb)\n\n\n\n\n\n\nThe layer can be saved as an RData object if needed. The size should be minimal (~1mb).\n\n# save the layer as an RData object (~1mb)\nsave(dattb, file = 'data/dattb.RData')\n\nUnlink the temporary files to delete them when you are finished.\n\nunlink(tmp1, recursive = TRUE)\nunlink(gdbpth, recursive = TRUE)"
  },
  {
    "objectID": "create.html",
    "href": "create.html",
    "title": "Mapping underserved communities",
    "section": "",
    "text": "The Tampa Bay Estuary Program (TBEP) is developing a methodology as part of its new Equity Strategy to identify historically underserved (i.e., disadvantaged) communities across the Tampa Bay watershed to support the goals of the White House’s Justice40 Initiative (EO 14008) and the Environmental Protection Agency’s Equity Action Plan (EO 13985). The purpose of this initiative is to ensure TBEP delivers equitable and fair access to the benefits from environmental programs for all communities.\nBelow, we have provided instructions for replicating our methodology for mapping underserved communities in Tampa Bay. To view instructions for downloading the necessary source data from EJScreen, see Getting EJScreen data.\nWhile we encourage other National Estuary Programs to adopt our methodology in their own Equity Strategies, we recognize that different approaches may be necessary in different areas. Along with our descriptions of the methodology, we also briefly highlight the rationale behind our decisions, which may or may not be relevant or appropriate for other NEPs. If you have questions or other feedback regarding the methodology, contact Dr. Blake Simmons at bsimmons@tbep.org.\nThe method described below is presented in R coding language, but users who prefer working with GIS software (e.g., ArcGIS or QGIS) should also be able to reproduce the maps by following along in the descriptions of each step.\nLoad the required R packages (install first as needed).\n\nlibrary(sf)\nlibrary(mapview)\nlibrary(dplyr)\nlibrary(RColorBrewer)\n\nLoad and view the data.\n\nload(file = 'data/dattb.RData')\nmapview(dattb)\n\n\n\n\n\n\nYou can see that some census tracts are only representative of the bay. We can clean up this data by retaining only the tracts in which the total population recorded in the latest American Community Survey (“ACSTOTPOP”) was above zero. This will remove tracts in which no people reside (e.g., large waterbodies, parks, or other natural areas).\nIn line with EPA recommendations, we will use the following five demographic variables to identify underserved communities:\n\nPercent classified as low income\nPercent unemployed\nPercent linguistically isolated (i.e., limited English speaking)\nPercent with less than a high school education\nPercent with low life expectancy\n\nThe EPA recommends flagging communities that fall within the 80th percentile (or higher) nationally as potentially disadvantaged. However, meeting this threshold in one variable alone is not necessarily an appropriate measure of disadvantage (e.g., a community of predominantly wealthy retirees would meet the unemployment threshold). For TBEP’s Equity Strategy, we define an underserved community as one that meets at least two of these thresholds, which we believe reduces the number of errors in identification while recognizing that a community does not need to meet the threshold of every indicator to face significant challenges.\nRun the code below to (1) remove unpopulated census tracts, (2) count the number of demographic thresholds met in each tract, and (3) identify which tracts will be classified as “underserved” communities.\n\ndattbindex <- dattb %>%\n  filter(ACSTOTPOP > 0) %>%\n  mutate(threshold_income = ifelse(P_LWINCPCT >= 80, 1, 0),\n         threshold_unempl = ifelse(P_UNEMPPCT >= 80, 1, 0),\n         threshold_lingui = ifelse(P_LNGISPCT >= 80, 1, 0),\n         threshold_educat = ifelse(P_LESHSPCT >= 80, 1, 0),\n         threshold_lifexp = ifelse(P_LIFEEXPCT >= 80, 1, 0)) %>%\n  rowwise() %>%\n  select(matches('^threshold|^ID')) %>% \n  mutate(threshold_N = sum(threshold_income,threshold_unempl,threshold_lingui,threshold_educat,threshold_lifexp, na.rm = TRUE)) %>%\n  mutate(underserved = ifelse(threshold_N > 1, \"Yes\", \"No\"))\n\nView the first five rows to see how the calculations have played out.\n\nhead(dattbindex)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -82.45127 ymin: 28.03256 xmax: -82.39752 ymax: 28.05464\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 9\n# Rowwise: \n  ID          thresh…¹ thres…² thres…³ thres…⁴ thres…⁵                     Shape\n  <chr>          <dbl>   <dbl>   <dbl>   <dbl>   <dbl>             <POLYGON [°]>\n1 12057000101        1       0       0       0      NA ((-82.42619 28.04506, -8…\n2 12057000102        1       1       1       1       0 ((-82.42633 28.03258, -8…\n3 12057000201        1       1       1       1       1 ((-82.4512 28.04362, -82…\n4 12057000202        1       1       1       1      NA ((-82.44289 28.05294, -8…\n5 12057000301        1       0       1       1       1 ((-82.45127 28.03364, -8…\n6 12057000302        1       0       0       1       1 ((-82.43595 28.0391, -82…\n# … with 2 more variables: threshold_N <dbl>, underserved <chr>, and\n#   abbreviated variable names ¹​threshold_income, ²​threshold_unempl,\n#   ³​threshold_lingui, ⁴​threshold_educat, ⁵​threshold_lifexp\n\n\nView a map showing the number of thresholds met per census tract (you may adapt to a different color scale of your choice).\n\nmapview(dattbindex, zcol = \"threshold_N\", col.regions = brewer.pal(6, \"Reds\"))\n\n\n\n\n\n\nView the tracts that meet our definition of underserved communities. The areas in red are those that rank in the 80th percentile (or greater) nationally in 2 or more of the demographic screening variables. They will serve as priority areas for increasing the equitable distribution of benefits from TBEP’s environmental programs.\n\nmapview(dattbindex, zcol = \"underserved\", col.regions = list(\"gray\",\"red\"))\n\n\n\n\n\n\nYou can save this final data as an RData object for future use.\n\n# save the layer as an RData object\nsave(dattbindex, file = 'data/dattbindex.RData')"
  }
]