[
  {
    "objectID": "cejst.html",
    "href": "cejst.html",
    "title": "Getting environmental justice data",
    "section": "",
    "text": "Under the new Equity Strategy, our goal is to ensure at least 40% of the benefits from TBEP activities are directed to underserved communities (see “Mapping underserved communities”). Many of these underserved communities are also disproportionately burdened by pollution, expected impacts from climate change, and lack of green space. Understanding which communities face different burdens can help TBEP prioritize different activities to help mitigate or reduce the burdens facing these communities.\nTBEP has selected the following 12 factors representing (1) those most relevant to the burdens facing communities in Tampa Bay and (2) environmental injustices that could be reduced by the benefits of TBEP activities:\nBelow, we have provided instructions for downloading, cleaning, and analyzing the data that will be used to characterize the burdens facing communities in Tampa Bay. To view instructions for utilizing the final data to map underserved and overburdened communities, see “Mapping underserved and overburdened communities.”\nThe method described below is presented in R coding language, but users who prefer working with GIS software (e.g., ArcGIS or QGIS) should also be able to reproduce the maps by following along in the descriptions of each step and using analogous GIS tools.\nLoad the required R packages (install first as needed, tbeptools installation instructions are here)"
  },
  {
    "objectID": "cejst.html#cejst-data",
    "href": "cejst.html#cejst-data",
    "title": "Getting environmental justice data",
    "section": "CEJST Data",
    "text": "CEJST Data\nThe U.S. Council on Environmental Quality has developed the Climate and Economic Justice Screening Tool (CEJST) to assist users in identifying overburdened communities using a similar methodology as EJScreen, in which national percentiles are used as thresholds for flagging census tracts that are significantly burdened by one or more indicators spanning climate change, energy, health, housing, pollution, and other dimensions. The data is available from https://screeningtool.geoplatform.gov/en/downloads.\nCEJST provides the percentiles we need for 10 out of the 12 variables we use for identifying overburdened communities. Below are brief descriptions of the variables and how they are estimated, and more information about the data, sources, and methodologies can be found here.\n\nExpected agricultural loss rate: Expected agricultural value at risk from losses due to fourteen types of natural hazards linked to climate change.\nProjected flood risk: Number of properties at risk of floods occurring in the next 30 years from tides, rain, riverine or storm surges based on a climate-adjusted model.\nPM2.5 in the air: Weight of fine inhalable particles (< 2.5 micrometers in diameter) per cubic meter.\nHistoric underinvestment: Census tracts that experienced historic underinvestment based on redlining maps created between 1935-1940.\nLack of green space: Share of land with developed surfaces covered with artificial materials (e.g. concrete, pavement).\nProximity to hazardous waste facilities: Number of hazardous waste facilities within 5 km (or nearest beyond 5 km) divided by distance.\nProximity to Superfund sites: Number of proposed or listed Superfund or National Priorities list (NPL) sites within 5 km (or nearest beyond 5 km) divided by distance.\nTraffic proximity and volume: Number of vehicles (average annual daily traffic) at major roads within 500 m, divided by distance.\nUnderground storage tanks and releases: Density of leaking underground storage tanks divided by all active underground storage tanks within 1,500 ft.\nWastewater discharge: Modeled toxic concentrations in stream segments within 500 m, divided by distance.\n\nDownload the CEJST zip file to temp directory and unzip to temp directory.\n\nurlin <- 'https://static-data-screeningtool.geoplatform.gov/data-versions/1.0/data/score/downloadable/1.0-shapefile-codebook.zip'\n\ntmp1 <- tempfile(fileext = \".zip\")\ndownload.file(url = urlin, destfile = tmp1)\n\ntmp2 <- tempdir()\nunzip(tmp1, exdir = tmp2)\n\nUnzip the ‘usa.zip’ file in the folder.\n\nzip1 <- list.files(tmp2, 'usa\\\\.zip', full.names = T)\nunzip(zip1, exdir = tmp2)\n\nGet file path for ‘usa.shp’ and import with sf.\n\ncejst <- list.files(tmp2, '\\\\.shp', full.names = T)\ndatcejst <- st_read(cejst)\n\nTo exclude census tracts outside of our watershed boundary, intersect the layer with the Tampa Bay watershed. If working in a different area, you will want to replace the tbshed shapefile with your own boundary file. In this case, the coordinate system is the same, so there’s no need to transform.\n\nload(file = 'data/tbshed.RData')\n\ndattbcejst <- datcejst %>% \n  st_intersection(tbshed)\n\nsave(dattbcejst, file = 'data/dattbcejst.RData')\n\nView the data. It will look similar to the EJScreen data.\n\nmapview(dattbcejst)\n\nUnfortunately, the census tracts from CEJST are not completely identical to the census tracts in EJScreen. The tracts provided by CEJST, when they do differ, are primarily at a larger scale (e.g., one CEJST tract may be split into 2 tracts in EJScreen data). We prefer to work from the higher resolution tracts (EJScreen), so we need to make sure, for each EJScreen tract, we pull the relevant data from the CEJST tract. Notably, some of the resulting tract data may not be entirely accurate, as percentiles may apply to the larger CEJST tract but not necessarily to the tracts as split by the EJScreen data. As of February 2023, the tract boundaries between EJScreen and CEJST have yet to be harmonized, but this may change in future versions of these tools.\nIf you’ve already created the ‘dattbindex’ shapefile from “Mapping underserved communities,” you can simply load that shapefile. Here, we’ll load the ‘dattb’ shapefile and quickly replicate the creation of ‘dattbindex’ as a reminder.\n\nload(file = 'data/dattb.RData')\n\ndattbindex <- dattb %>%\n  filter(ACSTOTPOP > 0) %>%\n  mutate(threshold_income = ifelse(P_LWINCPCT >= 80, 1, 0),\n         threshold_unempl = ifelse(P_UNEMPPCT >= 80, 1, 0),\n         threshold_lingui = ifelse(P_LNGISPCT >= 80, 1, 0),\n         threshold_educat = ifelse(P_LESHSPCT >= 80, 1, 0),\n         threshold_lifexp = ifelse(P_LIFEEXPCT >= 80, 1, 0)) %>%\n  rowwise() %>%\n  select(matches('^threshold|^ID')) %>% \n  mutate(threshold_N = sum(threshold_income,threshold_unempl,threshold_lingui,threshold_educat,threshold_lifexp, na.rm = TRUE)) %>%\n  mutate(underserved = ifelse(threshold_N > 1, \"Yes\", \"No\"))\n\nKeep only those tracts that are classified as underserved.\n\ndattbunder <- dattbindex %>%\n  filter(underserved == \"Yes\")\n\nmapview(dattbunder)\n\nWe will create representative points out of the underserved EJScreen tracts. We can then attribute the values of the underlying CEJST tracts to each point, and then merge those values into ‘dattbunder’. Similar to the thresholds defined for identifying underserved communities, we define “overburdened” communities as those that fall within the 80th percentile (or greater) nationally on at least 1 of the 12 measures of environmental justice outlined above.\n\ncejstvalues <- st_point_on_surface(dattbunder) %>%\n  st_intersection(dattbcejst) %>%\n  mutate(thresholdEJ_agloss = ifelse(EALR_PFS >= 0.80, 1, 0),\n         thresholdEJ_floodr = ifelse(FLD_PFS >= 0.80, 1, 0),\n         thresholdEJ_greens = ifelse(IS_PFS >= 0.80, 1, 0),\n         thresholdEJ_pm2.5 = ifelse(PM25F_PFS >= 0.80, 1, 0),\n         thresholdEJ_trafic = ifelse(TF_PFS >= 0.80, 1, 0),\n         thresholdEJ_wastew = ifelse(WF_PFS >= 0.80, 1, 0),\n         thresholdEJ_hwaste = ifelse(TSDF_PFS >= 0.80, 1, 0),\n         thresholdEJ_ugtank = ifelse(UST_PFS >= 0.80, 1, 0),\n         thresholdEJ_sfunds = ifelse(NPL_PFS >= 0.80, 1, 0),\n         thresholdEJ_redlin = ifelse(HRS_ET >= 0.80, 1, 0)) %>%\n  rowwise() %>%\n  select(matches('^thresholdEJ|^ID')) %>%\n  as.data.frame()\n\ndattbunder_cejst <- left_join(dattbunder, cejstvalues, by = 'ID')"
  },
  {
    "objectID": "cejst.html#mining-data",
    "href": "cejst.html#mining-data",
    "title": "Getting environmental justice data",
    "section": "Mining Data",
    "text": "Mining Data\nAlthough CEJST provides data on abandoned coal mines, phosphate mining is a unique characteristic of Florida, and especially Tampa Bay. Of the 78 phosphate mining operations in the U.S. recorded by the U.S. Geological Survey, 29 (37%) are located in Florida, and 13 (17%) are within the Tampa Bay watershed. The potential impacts of phosphate mining are thus a unique burden to communities in our watershed, which is why we have opted to include phosphate rather than coal mines in our identification of overburdened communities.\nSpatial data is available from the Florida Department of Environmental Protection (FDEP) here. This is provided as a polygon layer, showing all active mandatory phosphate mines in Florida as of 2019. See the FDEP website for more details on the dataset.\nThe shapefile can be read in directly with st_read.\n\nmined <- st_read('https://ca.dep.state.fl.us/arcgis/rest/services/OpenData/MMP_MINEDUNITS/MapServer/0/query?outFields=*&where=1%3D1&f=geojson')\nmapview(mined)\n\nCEJST considers any census tract containing abandoned coal mines to be significantly burdened. We adopt the same approach for phosphate mines in Tampa Bay. Create an indicator for tracts that overlap with the phosphate mining units.\n\nsf_use_s2(FALSE)\n\nmaxval <- dattbunder_cejst %>%\n  st_join(mined) %>%\n  mutate(SITE_ID = coalesce(SITE_ID, 0)) %>% \n  mutate(dummyvar = ifelse(SITE_ID > 0, 1, 0)) %>%\n  group_by(ID) %>%\n  summarise(thresholdEJ_phmine = max(dummyvar)) %>%\n  as.data.frame()\n\ndattbunder_cejst_mines <- left_join(dattbunder_cejst, maxval, by = 'ID')"
  },
  {
    "objectID": "cejst.html#brownfield-data",
    "href": "cejst.html#brownfield-data",
    "title": "Getting environmental justice data",
    "section": "Brownfield Data",
    "text": "Brownfield Data\nProperties in which expansion, redevelopment, or reuse may be complicated by the potential presence of contaminants, called “brownfields,” are another important burden to some communities in Tampa Bay. While CEJST and EJScreen do not include the proximity of census tracts to brownfield sites in their national percentiles, the EPA hosts a database with the lat/lon coordinates of brownfield properties, called the Assessment, Cleanup, and Redevelopment Exchange System (ACRES). The data is available as KML point data here.\nDownload the zipped KML file to a temporary directory.\n\n# url with zipped kml\nurlin <- 'https://ordsext.epa.gov/FLA/www3/acres_frs.kmz'\n\n# download file\ntmp1 <- tempfile(fileext = \".kmz\")\ndownload.file(url = urlin, destfile = tmp1, method = 'curl')\n\nUnzip the KMZ file.\n\ntmp2 <- tempdir()\nunzip(tmp1, exdir = tmp2)\n\nGet the name of the KML file to read.\n\nlyr <- unzip(tmp1, list = T)$Name\nfl <- paste(c(tmp2, lyr), collapse = \"\\\\\")\nfl <- gsub('\\\\\\\\', '/', fl)\n\nRead the KML file with st_read and drop the Z dimension with st_zm. Here, the Tampa sites are loaded. You can view all possible locations in the kml file with st_layers.\n\ndat <- st_read(fl, layer = 'TAMPA') %>% \n  st_zm()\nmapview(dat)\n\nUnlink the temporary files to delete them when you are finished.\n\nunlink(tmp1, recursive = TRUE)\nunlink(fl, recursive = TRUE)"
  },
  {
    "objectID": "importing.html",
    "href": "importing.html",
    "title": "Importing additional spatial data",
    "section": "",
    "text": "library(sf)\nlibrary(mapview)"
  },
  {
    "objectID": "importing.html#mined-units",
    "href": "importing.html#mined-units",
    "title": "Importing additional spatial data",
    "section": "Mined Units",
    "text": "Mined Units\nThe mined units can be read in directly with st_read.\n\nmined <- st_read('https://ca.dep.state.fl.us/arcgis/rest/services/OpenData/MMP_MINEDUNITS/MapServer/0/query?outFields=*&where=1%3D1&f=geojson')\n\nReading layer `OGRGeoJSON' from data source \n  `https://ca.dep.state.fl.us/arcgis/rest/services/OpenData/MMP_MINEDUNITS/MapServer/0/query?outFields=*&where=1%3D1&f=geojson' \n  using driver `GeoJSON'\nSimple feature collection with 371 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -82.95369 ymin: 27.46063 xmax: -81.69582 ymax: 30.51925\nGeodetic CRS:  WGS 84\n\nmapview(mined)"
  },
  {
    "objectID": "importing.html#brownfield-sites",
    "href": "importing.html#brownfield-sites",
    "title": "Importing additional spatial data",
    "section": "Brownfield sites",
    "text": "Brownfield sites\nDownload the zipped kml file to a temporary directory.\n\n# url with zipped kml\nurlin <- 'https://ordsext.epa.gov/FLA/www3/acres_frs.kmz'\n\n# download file\ntmp1 <- tempfile(fileext = \".kmz\")\ndownload.file(url = urlin, destfile = tmp1, method = 'curl')\n\nUnzip the kmz file.\n\ntmp2 <- tempdir()\nunzip(tmp1, exdir = tmp2)\n\nGet the name of the kml file to read.\n\nlyr <- unzip(tmp1, list = T)$Name\nfl <- paste(c(tmp2, lyr), collapse = \"\\\\\")\nfl <- gsub('\\\\\\\\', '/', fl)\n\nRead the kml file with st_read and drop Z dimension with st_zm. Here, the Tampa sites are loaded. You can view all possible locations in the kml file with st_layers.\n\ndat <- st_read(fl, layer = 'TAMPA') %>% \n  st_zm()\n\nReading layer `TAMPA' from data source `/tmp/Rtmp9F6B53/ACRES_FRS.KML' using driver `LIBKML'\nSimple feature collection with 103 features and 12 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: -82.51857 ymin: 27.87108 xmax: -82.3533 ymax: 28.07826\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nmapview(dat)\n\n\n\n\n\n\nUnlink the temporary files to delete them when you are finished.\n\nunlink(tmp1, recursive = TRUE)\nunlink(fl, recursive = TRUE)"
  },
  {
    "objectID": "importing.html#another-dataset",
    "href": "importing.html#another-dataset",
    "title": "Importing additional spatial data",
    "section": "Another dataset",
    "text": "Another dataset\nNot sure what this one is… but process is similar except two zip files have to be unzipped.\nDownload zip file to temp directory and unzip to temp directory.\n\nurlin <- 'https://static-data-screeningtool.geoplatform.gov/data-versions/1.0/data/score/downloadable/1.0-shapefile-codebook.zip'\n\ntmp1 <- tempfile(fileext = \".zip\")\ndownload.file(url = urlin, destfile = tmp1)\n\ntmp2 <- tempdir()\nunzip(tmp1, exdir = tmp2)\n\nUnzip usa.zip file.\n\nzip1 <- list.files(tmp2, 'usa\\\\.zip', full.names = T)\nunzip(zip1, exdir = tmp2)\n\nGet file path for usa.shp, import with sf.\n\nfl <- list.files(tmp2, '\\\\.shp', full.names = T)\ndat <- st_read(fl)\n\nReading layer `usa' from data source `/tmp/Rtmp9F6B53/usa.shp' using driver `ESRI Shapefile'\nSimple feature collection with 74134 features and 123 fields (with 367 geometries empty)\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.2311 ymin: -14.60181 xmax: 179.8597 ymax: 71.44106\nGeodetic CRS:  WGS 84\n\n\nClip to Tampa Bay watershed boundaries. CRS is the same, so no need to transform.\n\nload(file = 'data/tbshed.RData')\n\ndattb2 <- dat %>% \n  st_intersection(tbshed)\n\nsave(dattb2, file = 'data/dattb2.RData')\n\nView the data.\n\nmapview(dattb2)\n\n\n\n\n\n\nRemove temporary files.\n\nunlink(tmp1, recursive = TRUE)\nunlink(zip1)\nfls <- list.files(tmp2, gsub('\\\\.shp$', '', basename(fl)), full.names = T)\nfile.remove(fls)\n\n[1] TRUE TRUE TRUE TRUE TRUE"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Getting EJScreen data",
    "section": "",
    "text": "The Tampa Bay Estuary Program (TBEP) is developing a methodology as part of its new Equity Strategy to identify historically underserved (i.e., disadvantaged) communities across the Tampa Bay watershed to support the goals of the White House’s Justice40 Initiative (EO 14008) and the Environmental Protection Agency’s Equity Action Plan (EO 13985). The purpose of this initiative is to ensure TBEP delivers equitable and fair access to the benefits from environmental programs for all communities.\nBelow, we have provided instructions for downloading the data that will be used to identify underserved communities in Tampa Bay. To view instructions for cleaning the data and utilizing the demographic indices to map underserved communities, see Mapping underserved communities.\nThe method described below is presented in R coding language, but users who prefer working with GIS software (e.g., ArcGIS or QGIS) should also be able to reproduce the maps by following along in the descriptions of each step.\nLoad the required R packages (install first as needed).\n\nlibrary(sf)\nlibrary(mapview)\n\nTo collect demographic data that will be used for identifying underserved communities, we will be downloading U.S. census data provided by the EPA’s 2022 Environmental Justice Screening Tool (EJScreen). This data is available from https://gaftp.epa.gov/EJSCREEN/2022/. Here you will find different versions of EJScreen data that are summarized, calculated, and visualized in different ways to meet your particular needs (e.g., census blocks or tracts, state or national percentiles, tabular or spatial data).\nIn our case, we are interested in obtaining spatial data for the supplemental demographic indices, summarized at the census tract level, using national percentiles as our thresholds for identifying underserved communities. The appropriate file to download for our requirements is “EJSCREEN_2022_Supplemental_with_AS_CNMI_GU_VI_Tracts.gdb.zip”. However, you may want to explore the files available to see if a different file is more appropriate based on your needs.\nDownload the relevant file from EJScreen. The file is downloaded to a temporary directory.\n\n# url with zip gdb to download\nurlin <- 'https://gaftp.epa.gov/EJSCREEN/2022/EJSCREEN_2022_Supplemental_with_AS_CNMI_GU_VI_Tracts.gdb.zip'\n\n# download file\ntmp1 <- tempfile(fileext = \".zip\")\ndownload.file(url = urlin, destfile = tmp1)\n\nUnzip the geodatabase that was downloaded to a second temporary directory.\n\n# unzip file\ntmp2 <- tempdir()\nutils::unzip(tmp1, exdir = tmp2)\n\nRead the polygon layer from the geodatabase.\n\n# get the layers from the gdb\ngdbpth <- list.files(tmp2, pattern = '\\\\.gdb$', full.names = T)\ngdbpth <- gsub('\\\\\\\\', '/', gdbpth)\nlyr <- st_layers(gdbpth)$name\n\n# read the layer\ndat <- st_read(dsn = gdbpth, lyr)\n\nTo exclude census tracts outside of our watershed boundary, intersect the layer with the Tampa Bay watershed. If working in a different area, you will want to replace the tbshed shapefile with your own boundary file.\n\nload(file = 'data/tbshed.RData')\n\n# intersect the layer with the tb watershed\ndattb <- dat %>% \n  st_transform(crs = st_crs(tbshed)) %>% \n  st_make_valid() %>% \n  st_intersection(tbshed)\n\nView the data using mapview. You can see that we now have the desired spatial data just for our watershed.\n\n\n\n\nmapview(dattb)\n\n\n\n\n\n\nThe layer can be saved as an RData object if needed. The size should be minimal (~1mb).\n\n# save the layer as an RData object (~1mb)\nsave(dattb, file = 'data/dattb.RData')\n\nUnlink the temporary files to delete them when you are finished.\n\nunlink(tmp1, recursive = TRUE)\nunlink(gdbpth, recursive = TRUE)"
  },
  {
    "objectID": "create.html",
    "href": "create.html",
    "title": "Mapping underserved communities",
    "section": "",
    "text": "The Tampa Bay Estuary Program (TBEP) is developing a methodology as part of its new Equity Strategy to identify historically underserved (i.e., disadvantaged) communities across the Tampa Bay watershed to support the goals of the White House’s Justice40 Initiative (EO 14008) and the Environmental Protection Agency’s Equity Action Plan (EO 13985). The purpose of this initiative is to ensure TBEP delivers equitable and fair access to the benefits from environmental programs for all communities.\nBelow, we have provided instructions for replicating our methodology for mapping underserved communities in Tampa Bay. To view instructions for downloading the necessary source data from EJScreen, see Getting EJScreen data.\nWhile we encourage other National Estuary Programs to adopt our methodology in their own Equity Strategies, we recognize that different approaches may be necessary in different areas. Along with our descriptions of the methodology, we also briefly highlight the rationale behind our decisions, which may or may not be relevant or appropriate for other NEPs. If you have questions or other feedback regarding the methodology, contact Dr. Blake Simmons at bsimmons@tbep.org.\nThe method described below is presented in R coding language, but users who prefer working with GIS software (e.g., ArcGIS or QGIS) should also be able to reproduce the maps by following along in the descriptions of each step.\nLoad the required R packages (install first as needed).\n\nlibrary(sf)\nlibrary(mapview)\nlibrary(dplyr)\nlibrary(RColorBrewer)\n\nLoad and view the data.\n\nload(file = 'data/dattb.RData')\nmapview(dattb)\n\n\n\n\n\n\nYou can see that some census tracts are only representative of the bay. We can clean up this data by retaining only the tracts in which the total population recorded in the latest American Community Survey (“ACSTOTPOP”) was above zero. This will remove tracts in which no people reside (e.g., large waterbodies, parks, or other natural areas).\nIn line with EPA recommendations, we will use the following five demographic variables to identify underserved communities:\n\nPercent classified as low income\nPercent unemployed\nPercent linguistically isolated (i.e., limited English speaking)\nPercent with less than a high school education\nPercent with low life expectancy\n\nThe EPA recommends flagging communities that fall within the 80th percentile (or higher) nationally as potentially disadvantaged. However, meeting this threshold in one variable alone is not necessarily an appropriate measure of disadvantage (e.g., a community of predominantly wealthy retirees would meet the unemployment threshold). For TBEP’s Equity Strategy, we define an underserved community as one that meets at least two of these thresholds, which we believe reduces the number of errors in identification while recognizing that a community does not need to meet the threshold of every indicator to face significant challenges.\nRun the code below to (1) remove unpopulated census tracts, (2) count the number of demographic thresholds met in each tract, and (3) identify which tracts will be classified as “underserved” communities.\n\ndattbindex <- dattb %>%\n  filter(ACSTOTPOP > 0) %>%\n  mutate(threshold_income = ifelse(P_LWINCPCT >= 80, 1, 0),\n         threshold_unempl = ifelse(P_UNEMPPCT >= 80, 1, 0),\n         threshold_lingui = ifelse(P_LNGISPCT >= 80, 1, 0),\n         threshold_educat = ifelse(P_LESHSPCT >= 80, 1, 0),\n         threshold_lifexp = ifelse(P_LIFEEXPCT >= 80, 1, 0)) %>%\n  rowwise() %>%\n  select(matches('^threshold|^ID')) %>% \n  mutate(threshold_N = sum(threshold_income,threshold_unempl,threshold_lingui,threshold_educat,threshold_lifexp, na.rm = TRUE)) %>%\n  mutate(underserved = ifelse(threshold_N > 1, \"Yes\", \"No\"))\n\nView the first five rows to see how the calculations have played out.\n\nhead(dattbindex)\n\nSimple feature collection with 6 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -82.45127 ymin: 28.03256 xmax: -82.39752 ymax: 28.05464\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 9\n# Rowwise: \n  ID          thresh…¹ thres…² thres…³ thres…⁴ thres…⁵                     Shape\n  <chr>          <dbl>   <dbl>   <dbl>   <dbl>   <dbl>             <POLYGON [°]>\n1 12057000101        1       0       0       0      NA ((-82.42619 28.04506, -8…\n2 12057000102        1       1       1       1       0 ((-82.42633 28.03258, -8…\n3 12057000201        1       1       1       1       1 ((-82.4512 28.04362, -82…\n4 12057000202        1       1       1       1      NA ((-82.44289 28.05294, -8…\n5 12057000301        1       0       1       1       1 ((-82.45127 28.03364, -8…\n6 12057000302        1       0       0       1       1 ((-82.43595 28.0391, -82…\n# … with 2 more variables: threshold_N <dbl>, underserved <chr>, and\n#   abbreviated variable names ¹​threshold_income, ²​threshold_unempl,\n#   ³​threshold_lingui, ⁴​threshold_educat, ⁵​threshold_lifexp\n\n\nView a map showing the number of thresholds met per census tract (you may adapt to a different color scale of your choice).\n\nmapview(dattbindex, zcol = \"threshold_N\", col.regions = brewer.pal(6, \"Reds\"))\n\n\n\n\n\n\nView the tracts that meet our definition of underserved communities. The areas in red are those that rank in the 80th percentile (or greater) nationally in 2 or more of the demographic screening variables. They will serve as priority areas for increasing the equitable distribution of benefits from TBEP’s environmental programs.\n\nmapview(dattbindex, zcol = \"underserved\", col.regions = list(\"gray\",\"red\"))\n\n\n\n\n\n\nYou can save this final data as an RData object for future use.\n\n# save the layer as an RData object\nsave(dattbindex, file = 'data/dattbindex.RData')"
  }
]