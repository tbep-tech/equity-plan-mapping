[
  {
    "objectID": "cejst.html",
    "href": "cejst.html",
    "title": "Getting environmental justice data",
    "section": "",
    "text": "Under the new Equity Strategy, our goal is to ensure at least 40% of the benefits from TBEP activities are directed to underserved communities (see Mapping underserved communities). Many of these underserved communities are also disproportionately burdened by pollution, expected impacts from climate change, and lack of green space. Understanding which communities face different burdens can help TBEP prioritize different activities to help mitigate or reduce the burdens facing these communities.\nTBEP has selected the following 12 factors representing (1) those most relevant to the burdens facing communities in Tampa Bay and (2) environmental injustices that could be reduced by the benefits of TBEP activities:\nBelow, we have provided instructions for downloading, cleaning, and analyzing the data that will be used to characterize the burdens facing communities in Tampa Bay. To view instructions for utilizing the final data to map underserved and overburdened communities, see Mapping underserved and overburdened communities.\nLoad the required R packages (install first as needed)."
  },
  {
    "objectID": "cejst.html#cejst-data",
    "href": "cejst.html#cejst-data",
    "title": "Getting environmental justice data",
    "section": "CEJST Data",
    "text": "CEJST Data\nThe U.S. Council on Environmental Quality has developed the Climate and Economic Justice Screening Tool (CEJST) to assist users in identifying overburdened communities using a similar methodology as EJScreen, in which national percentiles are used as thresholds for flagging census tracts that are significantly burdened by one or more indicators spanning climate change, energy, health, housing, pollution, and other dimensions. The data is available from https://screeningtool.geoplatform.gov/en/downloads.\nCEJST provides the percentiles we need for 10 out of the 12 variables we use for identifying overburdened communities. Below are brief descriptions of the variables and how they are estimated, and more information about the data, sources, and methodologies can be found here.\n\nExpected agricultural loss rate: Expected agricultural value at risk from losses due to fourteen types of natural hazards linked to climate change.\nProjected flood risk: Number of properties at risk of floods occurring in the next 30 years from tides, rain, riverine or storm surges based on a climate-adjusted model.\nPM2.5 in the air: Weight of fine inhalable particles (< 2.5 micrometers in diameter) per cubic meter.\nHistoric underinvestment: Census tracts that experienced historic underinvestment based on redlining maps created between 1935-1940.\nLack of green space: Share of land with developed surfaces covered with artificial materials (e.g. concrete, pavement).\nProximity to hazardous waste facilities: Number of hazardous waste facilities within 5 km (or nearest beyond 5 km) divided by distance.\nProximity to Superfund sites: Number of proposed or listed Superfund or National Priorities list (NPL) sites within 5 km (or nearest beyond 5 km) divided by distance.\nTraffic proximity and volume: Number of vehicles (average annual daily traffic) at major roads within 500 m, divided by distance.\nUnderground storage tanks and releases: Density of leaking underground storage tanks divided by all active underground storage tanks within 1,500 ft.\nWastewater discharge: Modeled toxic concentrations in stream segments within 500 m, divided by distance.\n\nDownload the CEJST zip file to temp directory and unzip to temp directory.\n\nurlin <- 'https://static-data-screeningtool.geoplatform.gov/data-versions/1.0/data/score/downloadable/1.0-shapefile-codebook.zip'\n\ntmp1 <- tempfile(fileext = \".zip\")\ndownload.file(url = urlin, destfile = tmp1)\n\ntmp2 <- tempdir()\nunzip(tmp1, exdir = tmp2)\n\nUnzip the ‘usa.zip’ file in the folder.\n\nzip1 <- list.files(tmp2, 'usa\\\\.zip', full.names = T)\nunzip(zip1, exdir = tmp2)\n\nGet file path for ‘usa.shp’ and import with sf.\n\ncejst <- list.files(tmp2, '\\\\.shp', full.names = T)\ndatcejst <- st_read(cejst)\n\nTo exclude census tracts outside of our watershed boundary, intersect the layer with the Tampa Bay watershed. If working in a different area, you will want to replace the tbshed shapefile with your own boundary file. In this case, the coordinate system is the same, so there’s no need to transform.\n\nload(file = 'data/tbshed.RData')\n\ndattbcejst <- datcejst %>% \n  st_intersection(tbshed)\n\nsave(dattbcejst, file = 'data/dattbcejst.RData')\n\nView the data. It will look similar to the EJScreen data.\n\n\n\n\nmapview(dattbcejst)\n\n\n\n\n\n\nUnfortunately, the census tracts from CEJST are not completely identical to the census tracts in EJScreen. The tracts provided by CEJST, when they do differ, are primarily at a larger scale (e.g., one CEJST tract may be split into 2 tracts in EJScreen data). We prefer to work from the higher resolution tracts (EJScreen), so we need to make sure, for each EJScreen tract, we pull the relevant data from the CEJST tract. Notably, some of the resulting tract data may not be entirely accurate, as percentiles may apply to the larger CEJST tract but not necessarily to the tracts as split by the EJScreen data. As of February 2023, the tract boundaries between EJScreen and CEJST have yet to be harmonized, but this may change in future versions of these tools.\nIf you’ve already created the ‘dattbindex’ shapefile from “Mapping underserved communities,” you can simply load that shapefile. Here, we’ll load the ‘dattb’ shapefile and quickly replicate the creation of ‘dattbindex’ as a reminder.\n\n# if saved\nload(file = 'data/dattbindex.Rdata')\n\n# otherwise replicate\nload(file = 'data/dattb.RData')\n\ndattbindex <- dattb %>%\n  filter(ACSTOTPOP > 0) %>%\n  mutate(threshold_income = ifelse(P_LWINCPCT >= 80, 1, 0),\n         threshold_unempl = ifelse(P_UNEMPPCT >= 80, 1, 0),\n         threshold_lingui = ifelse(P_LNGISPCT >= 80, 1, 0),\n         threshold_educat = ifelse(P_LESHSPCT >= 80, 1, 0),\n         threshold_lifexp = ifelse(P_LIFEEXPCT >= 80, 1, 0)) %>%\n  rowwise() %>%\n  select(matches('^threshold|^ID')) %>% \n  mutate(threshold_N = sum(threshold_income,threshold_unempl,threshold_lingui,threshold_educat,threshold_lifexp, na.rm = TRUE)) %>%\n  mutate(underserved = ifelse(threshold_N > 1, \"Yes\", \"No\"))\n\nKeep only those tracts that are classified as underserved.\n\n\n\n\ndattbunder <- dattbindex %>%\n  filter(underserved == \"Yes\")\n\nmapview(dattbunder, layer.name = \"Underserved Communities\")\n\n\n\n\n\n\nWe will create representative points out of the underserved EJScreen tracts. We can then attribute the values of the underlying CEJST tracts to each point, and then merge those values into ‘dattbunder’. Similar to the thresholds defined for identifying underserved communities, we define “overburdened” communities as those that fall within the 80th percentile (or greater) nationally on at least 1 of the 12 measures of environmental justice outlined above.\n\ncejstvalues <- st_point_on_surface(dattbunder) %>%\n  st_intersection(dattbcejst) %>%\n  mutate(thresholdEJ_agloss = ifelse(EALR_PFS >= 0.80, 1, 0),\n         thresholdEJ_floodr = ifelse(FLD_PFS >= 0.80, 1, 0),\n         thresholdEJ_greens = ifelse(IS_PFS >= 0.80, 1, 0),\n         thresholdEJ_pm2.5 = ifelse(PM25F_PFS >= 0.80, 1, 0),\n         thresholdEJ_trafic = ifelse(TF_PFS >= 0.80, 1, 0),\n         thresholdEJ_wastew = ifelse(WF_PFS >= 0.80, 1, 0),\n         thresholdEJ_hwaste = ifelse(TSDF_PFS >= 0.80, 1, 0),\n         thresholdEJ_ugtank = ifelse(UST_PFS >= 0.80, 1, 0),\n         thresholdEJ_sfunds = ifelse(NPL_PFS >= 0.80, 1, 0),\n         thresholdEJ_redlin = ifelse(HRS_ET >= 0.80, 1, 0)) %>%\n  rowwise() %>%\n  select(matches('^thresholdEJ|^ID')) %>%\n  as.data.frame()\n\ndattbunder_cejst <- left_join(dattbunder, cejstvalues, by = 'ID')"
  },
  {
    "objectID": "cejst.html#mining-data",
    "href": "cejst.html#mining-data",
    "title": "Getting environmental justice data",
    "section": "Mining Data",
    "text": "Mining Data\nAlthough CEJST provides data on abandoned coal mines, phosphate mining is a unique characteristic of Florida, and especially Tampa Bay. Of the 78 phosphate mining operations in the U.S. recorded by the U.S. Geological Survey, 29 (37%) are located in Florida, and 13 (17%) are within the Tampa Bay watershed. The potential impacts of phosphate mining are thus a unique burden to communities in our watershed, which is why we have opted to include phosphate rather than coal mines in our identification of overburdened communities.\nSpatial data is available from the Florida Department of Environmental Protection (FDEP) here. This is provided as a polygon layer, showing all active mandatory phosphate mines in Florida as of 2019. See the FDEP website for more details on the dataset.\nThe shapefile can be read in directly with st_read.\n\nmined <- st_read('https://ca.dep.state.fl.us/arcgis/rest/services/OpenData/MMP_MINEDUNITS/MapServer/0/query?outFields=*&where=1%3D1&f=geojson')\nmapview(mined)\n\nCEJST considers any census tract containing abandoned coal mines to be significantly burdened. We adopt the same approach for phosphate mines in Tampa Bay. Create an indicator for tracts that overlap with the phosphate mining units.\n\nsf_use_s2(FALSE)\n\nmaxval <- dattbunder_cejst %>%\n  st_join(mined) %>%\n  mutate(SITE_ID = coalesce(SITE_ID, 0)) %>% \n  mutate(dummyvar = ifelse(SITE_ID > 0, 1, 0)) %>%\n  group_by(ID) %>%\n  summarise(thresholdEJ_phmine = max(dummyvar)) %>%\n  as.data.frame()\n\ndattbunder_cejst_mines <- left_join(dattbunder_cejst, maxval, by = 'ID')"
  },
  {
    "objectID": "cejst.html#brownfield-data",
    "href": "cejst.html#brownfield-data",
    "title": "Getting environmental justice data",
    "section": "Brownfield Data",
    "text": "Brownfield Data\nProperties in which expansion, redevelopment, or reuse may be complicated by the potential presence of contaminants, called “brownfields,” are another important burden to some communities in Tampa Bay. While CEJST and EJScreen do not include the proximity of census tracts to brownfield sites in their national percentiles, the EPA hosts a database with the lat/lon coordinates of brownfield properties, called the Assessment, Cleanup, and Redevelopment Exchange System (ACRES). The data is available as KML point data here.\nDownload the zipped KML file to a temporary directory.\n\n# url with zipped kml\nurlin <- 'https://ordsext.epa.gov/FLA/www3/acres_frs.kmz'\n\n# download file\ntmp1 <- tempfile(fileext = \".kmz\")\ndownload.file(url = urlin, destfile = tmp1, method = 'curl')\n\nUnzip the KMZ file.\n\ntmp2 <- tempdir()\nunzip(tmp1, exdir = tmp2)\n\nGet the name of the KML file to read.\n\nlyr <- unzip(tmp1, list = T)$Name\nfl <- paste(c(tmp2, lyr), collapse = \"\\\\\")\nfl <- gsub('\\\\\\\\', '/', fl)\n\nRead the KML file with st_read and drop the Z dimension with st_zm. If you would like to only view brownfield sites in a particular area, below is an example for loading just the sites in the Tampa layer. You can view all possible locations in the kml file with st_layers. However, we need to create our brownfield metric using the nation-wide data, so you can skip this step.\n\ndat <- st_read(fl, layer = 'TAMPA') %>% \n  st_zm()\n\nTo import all layers in the kml file, identify the layer names and loop through them to add to a single object. The data are saved as an .Rdata object and .csv file for later use. The data include only the site name and location in decimal degrees.\nNOTE: This code takes several hours to complete. We have provided the code so that you may replicate this approach if desired, but for the sake of time, we recommend loading the Rdata object we have saved already (next step).\n\n# layer names\nalllyr <- st_layers(fl)$name\n\nstrt <- Sys.time()\nout <- NULL\nfor(i in alllyr){\n  \n  # counter\n  cat(i, which(i == alllyr), 'of', length(alllyr), '\\n')\n  print(Sys.time() - strt)\n  \n  # import each layer\n  dat <- st_read(fl, i, quiet = T)[, c('Name')]\n  \n  # append to same object\n  out <- rbind(out, dat)\n  \n}\n\n# save as RData object\nallbfld <- out %>% st_zm()\nsave(allbfld, file = 'data/allbfld.RData', compress = 'xz')\n\n# save as csv\nallbfldcsv <- allbfld %>% \n  mutate(\n    lon = st_coordinates(.)[,1], \n    lat = st_coordinates(.)[,2]\n  ) %>% \n  st_set_geometry(NULL)\nwrite.csv(allbfldcsv, 'data/allbfldcsv.csv', row.names = F)\n\nLoad and view the brownfield sites.\n\nload(file = 'data/allbfld.RData')\nmapview(allbfld, legend = F, col.regions = 'brown')\n\n\n\n\n\n\nYou can see the locations of all brownfield sites from the ACRES database across the country. We will use this data in a manner consistent with how CEJST measures a community’s proximity to hazardous waste facilities and Superfund sites.\nLoad the national census tract data from EJScreen if you have it saved from Getting demographic data. If not, download the data again using the same steps as before.\n\n# url with zip gdb to download\nurlin <- 'https://gaftp.epa.gov/EJSCREEN/2022/EJSCREEN_2022_Supplemental_with_AS_CNMI_GU_VI_Tracts.gdb.zip'\n\n# download file\ntmp1 <- tempfile(fileext = \".zip\")\ndownload.file(url = urlin, destfile = tmp1)\n\n# unzip file\ntmp2 <- tempdir()\nutils::unzip(tmp1, exdir = tmp2)\n\n# get the layers from the gdb\ngdbpth <- list.files(tmp2, pattern = '\\\\.gdb$', full.names = T)\ngdbpth <- gsub('\\\\\\\\', '/', gdbpth)\nlyr <- st_layers(gdbpth)$name\n\n# read the layer, keep only the tract ID to reduce size\nejscreen <- st_read(dsn = gdbpth, lyr) %>%\n  rowwise() %>%\n  select(matches('^ID')) \n\nFirst, we need to transform the brownfield and national EJScreen census tract data to an appropriate projected coordinate system so we can reliably calculate distances. For the U.S. (including Alaska and Hawaii), we will use the North America Albers Equal Area Conic (EPSG: 9822) projection.\n\nbfields <- st_transform(allbfld, crs = 9822)\ntracts <- st_transform(ejscreen, crs = 9822)\n\nIn line with the methodology for calculating proximity to hazardous waste facilities and Superfund sites, we will calculate each census tract’s proximity to brownfield sites as (1) the number of brownfield sites within 5 km of the tract divided by 5 km, or (2) if there are no sites within 5 km, then 1 divided by the distance to the nearest site. We will use Euclidean distances. Note that the units for distances will be in meters.\n\n# 5 km buffer (this will take several minutes)\ntractsbuff <- st_buffer(tracts, dist = 5000, endCapStyle = \"ROUND\")\n\n# number of brownfield sites within 5 km\ntractsbuff$brownfields_N <- lengths(st_intersects(tractsbuff, bfields))\n\n# distance to nearest brownfield site\nnearest <- st_nearest_feature(tracts, bfields)\ndistance <- st_distance(tracts, bfields[nearest,], by_element=TRUE)\njoined <- cbind(tracts, st_drop_geometry(bfields)[nearest,]) %>%\n  mutate(dist_m = distance) %>%\n  as.data.frame()\n\nproxbfield <- left_join(tractsbuff, joined, by = 'ID') %>%\n  as.data.frame() %>%\n  mutate(proximity = ifelse(brownfields_N > 0, brownfields_N/5000, 1/dist_m),\n         percentile = ntile(proximity, 100),\n         thresholdEJ_bfield = ifelse(percentile >= 80, 1, 0))\n\ndattbunder_cejst_mines_bfields <- left_join(dattbunder_cejst_mines, proxbfield, by = 'ID') %>%\n  mutate(thresholdEJ_N = sum(thresholdEJ_agloss,thresholdEJ_floodr,thresholdEJ_greens,thresholdEJ_pm2.5,thresholdEJ_trafic,thresholdEJ_wastew,thresholdEJ_hwaste,thresholdEJ_ugtank,thresholdEJ_sfunds,thresholdEJ_redlin,thresholdEJ_phmine,thresholdEJ_bfield, na.rm = TRUE)) %>%\n  mutate(overburdened = ifelse(thresholdEJ_N > 0, \"Yes\", \"No\")) %>%\n  rowwise() %>%\n  select(matches('^threshold|^ID|^under|^over'))\n\nSave this final layer as an RData object for future use.\n\n# save the layer as an RData object\ndattbunderover <- dattbunder_cejst_mines_bfields\nsave(dattbunderover, file = 'data/dattbunderover.RData')\n\nUnlink the temporary files to delete them when you are finished.\n\nunlink(tmp1, recursive = TRUE)\nunlink(gdbpth, recursive = TRUE)\nunlink(fl, recursive = TRUE)"
  },
  {
    "objectID": "ejscreen.html",
    "href": "ejscreen.html",
    "title": "Getting demographic data",
    "section": "",
    "text": "Below, we have provided instructions for downloading the data that will be used to identify underserved communities in Tampa Bay. To view instructions for cleaning the data and utilizing the demographic indices to map underserved communities, see Mapping underserved communities.\nLoad the required R packages (install first as needed).\n\nlibrary(sf)\nlibrary(mapview)\n\nTo collect demographic data that will be used for identifying underserved communities, we will be downloading U.S. census data provided by the EPA’s 2022 Environmental Justice Screening Tool (EJScreen). This data is available from https://gaftp.epa.gov/EJSCREEN/2022/. Here you will find different versions of EJScreen data that are summarized, calculated, and visualized in different ways to meet your particular needs (e.g., census blocks or tracts, state or national percentiles, tabular or spatial data).\nIn our case, we are interested in obtaining spatial data for the supplemental demographic indices, summarized at the census tract level, using national percentiles as our thresholds for identifying underserved communities. The appropriate file to download for our requirements is “EJSCREEN_2022_Supplemental_with_AS_CNMI_GU_VI_Tracts.gdb.zip”. However, you may want to explore the files available to see if a different file is more appropriate based on your needs.\nDownload the relevant file from EJScreen. The file is downloaded to a temporary directory.\n\n# url with zip gdb to download\nurlin <- 'https://gaftp.epa.gov/EJSCREEN/2022/EJSCREEN_2022_Supplemental_with_AS_CNMI_GU_VI_Tracts.gdb.zip'\n\n# download file\ntmp1 <- tempfile(fileext = \".zip\")\ndownload.file(url = urlin, destfile = tmp1)\n\nUnzip the geodatabase that was downloaded to a second temporary directory.\n\n# unzip file\ntmp2 <- tempdir()\nutils::unzip(tmp1, exdir = tmp2)\n\nRead the polygon layer from the geodatabase.\n\n# get the layers from the gdb\ngdbpth <- list.files(tmp2, pattern = '\\\\.gdb$', full.names = T)\ngdbpth <- gsub('\\\\\\\\', '/', gdbpth)\nlyr <- st_layers(gdbpth)$name\n\n# read the layer\ndat <- st_read(dsn = gdbpth, lyr)\n\nTo exclude census tracts outside of our watershed boundary, intersect the layer with the Tampa Bay watershed. If working in a different area, you will want to replace the tbshed shapefile with your own boundary file.\n\nload(file = 'data/tbshed.RData')\n\n# intersect the layer with the tb watershed\ndattb <- dat %>% \n  st_transform(crs = st_crs(tbshed)) %>% \n  st_make_valid() %>% \n  st_intersection(tbshed)\n\nView the data using mapview. You can see that we now have the desired spatial data just for our watershed.\n\n\n\n\nmapview(dattb)\n\n\n\n\n\n\nThe layer can be saved as an RData object if needed. The size should be minimal (~1mb).\n\n# save the layer as an RData object (~1mb)\nsave(dattb, file = 'data/dattb.RData')\n\nUnlink the temporary files to delete them when you are finished.\n\nunlink(tmp1, recursive = TRUE)\nunlink(gdbpth, recursive = TRUE)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Equity strategy overview",
    "section": "",
    "text": "The Tampa Bay Estuary Program (TBEP) is developing a methodology as part of its new Equity Strategy to identify historically underserved (i.e., disadvantaged) communities across the Tampa Bay watershed to support the goals of the White House’s Justice40 Initiative (EO 14008) and the Environmental Protection Agency’s Equity Action Plan (EO 13985). The purpose of this initiative is to ensure TBEP delivers equitable and fair access to the benefits from environmental programs for all communities.\nWe have created this webpage to increase transparency and reproducibility of the approach guiding our Equity Strategy. We have provided instructions for downloading, cleaning, and analyzing the data that will be used to identify underserved and overburdened communities in Tampa Bay. The methods described on the subsequent pages are presented in R coding language, but users who prefer working with GIS software (e.g., ArcGIS or QGIS) should also be able to reproduce the maps by following along in the descriptions of each step.\nWhile we encourage other National Estuary Programs to adopt our methodology in their own Equity Strategies, we recognize that different approaches may be necessary in different areas. Along with our descriptions of the methodology, we also briefly highlight the rationale behind our decisions, which may or may not be relevant or appropriate to other NEPs. If you have questions or other feedback regarding the methodology, contact Dr. Blake Simmons at bsimmons@tbep.org."
  },
  {
    "objectID": "underserved.html",
    "href": "underserved.html",
    "title": "Mapping underserved communities",
    "section": "",
    "text": "Below, we have provided instructions for replicating our methodology for mapping underserved communities in Tampa Bay. To view instructions for downloading the necessary source data from EJScreen, see Getting demographic data.\nLoad the required R packages (install first as needed).\nLoad and view the data.\nYou can see that some census tracts are only representative of the bay. We can clean up this data by retaining only the tracts in which the total population recorded in the latest American Community Survey (“ACSTOTPOP”) was above zero. This will remove tracts in which no people reside (e.g., large waterbodies, parks, or other natural areas).\nIn line with EPA recommendations, we will use the following five demographic variables to identify underserved communities:\nThe EPA recommends flagging communities that fall within the 80th percentile (or higher) nationally as potentially disadvantaged. However, meeting this threshold in one variable alone is not necessarily an appropriate measure of disadvantage (e.g., a community of predominantly wealthy retirees would meet the unemployment threshold). For TBEP’s Equity Strategy, we define an underserved community as one that meets at least two of these thresholds, which we believe reduces the number of errors in identification while recognizing that a community does not need to meet the threshold of every indicator to face significant challenges.\nRun the code below to (1) remove unpopulated census tracts, (2) count the number of demographic thresholds met in each tract, and (3) identify which tracts will be classified as “underserved” communities.\nView the first five rows to see how the calculations have played out."
  },
  {
    "objectID": "underserved.html#view-by-census-tract",
    "href": "underserved.html#view-by-census-tract",
    "title": "Mapping underserved communities",
    "section": "View by Census Tract",
    "text": "View by Census Tract\nView a map showing the number of thresholds met per census tract (you may adapt to a different color scale of your choice).\n\nmapview(dattbindex, zcol = \"threshold_N\", col.regions = brewer.pal(6, \"Reds\"), layer.name = \"No. of Thresholds Met\")\n\n\n\n\n\n\nView the tracts that meet our definition of underserved communities. The areas in red are those that rank in the 80th percentile (or greater) nationally in 2 or more of the demographic screening variables. They will serve as priority areas for increasing the equitable distribution of benefits from TBEP’s environmental programs.\n\nmapview(dattbindex, zcol = \"underserved\", col.regions = list(\"gray\",\"red\"), layer.name = \"Underserved Communities\")\n\n\n\n\n\n\nYou can save this final data as an RData object for future use.\n\n# save the layer as an RData object\nsave(dattbindex, file = 'data/dattbindex.RData')"
  },
  {
    "objectID": "underserved.html#view-by-drainage-basin",
    "href": "underserved.html#view-by-drainage-basin",
    "title": "Mapping underserved communities",
    "section": "View by Drainage Basin",
    "text": "View by Drainage Basin\nWhile the census tract delineations provide a practical map for identifying target neighborhoods and stakeholders that may be working for or in these underserved communities, it is not well-aligned with geographic delineations that are most informative for planning conservation and and restoration projects across the watershed.\nFor environmental planning purposes, TBEP will thus characterize unique water body assessment units according to the proportion of each unit containing underserved census tracts. This approach serves as a bridge between social and ecological units relevant to different stakeholders across Tampa Bay.\nThe Florida Department of Environmental Protection provides the Waterbody IDs (WBIDs) dataset, available here, which includes polygons delineating the drainage basins surrounding water body assessment units.\nLoad the drainage basin data.\n\ndbasins <- st_read('https://ca.dep.state.fl.us/arcgis/rest/services/OpenData/WBIDS/MapServer/0/query?outFields=*&where=1%3D1&f=geojson')\n\nReading layer `OGRGeoJSON' from data source \n  `https://ca.dep.state.fl.us/arcgis/rest/services/OpenData/WBIDS/MapServer/0/query?outFields=*&where=1%3D1&f=geojson' \n  using driver `GeoJSON'\nSimple feature collection with 6788 features and 17 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.6349 ymin: 24.39631 xmax: -79.97431 ymax: 31.00065\nGeodetic CRS:  WGS 84\n\n\nIntersect the layer with the Tampa Bay watershed.\n\nload(file = 'data/tbshed.RData')\n\nsf_use_s2(FALSE)\n\ndattbdbasins <- dbasins %>% \n  st_intersection(tbshed)\n\nSince we will be doing area calculations, we need to set a projected coordinate system for the drainage basin and census tract layers. The most appropriate CRS for Tampa Bay is EPSG 6443.\n\ndattbdbasins <- st_transform(dattbdbasins, crs = 6443)\ndattbindex <- st_transform(dattbindex, crs = 6443)\n\nKeep only the land area within each drainage basin and census tract. We can exclude water areas by intersecting the layers with Florida’s shoreline (available here from the Florida Fish and Wildlife Conservation Commission).\n\nflshore <- st_read('https://atoll.floridamarine.org/arcgis/rest/services/FWC_GIS/OpenData_Shoreline/MapServer/0/query?outFields=*&where=1%3D1&f=geojson')\n\nReading layer `OGRGeoJSON' from data source \n  `https://atoll.floridamarine.org/arcgis/rest/services/FWC_GIS/OpenData_Shoreline/MapServer/0/query?outFields=*&where=1%3D1&f=geojson' \n  using driver `GeoJSON'\nSimple feature collection with 15470 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: -87.63477 ymin: 24.52114 xmax: -80.03118 ymax: 31.00091\nGeodetic CRS:  WGS 84\n\nflshore <- st_transform(flshore, crs = 6443)\n\ndattbdbasins <- dattbdbasins %>% \n  st_intersection(flshore)\n\ndattbindex <- dattbindex %>% \n  st_intersection(flshore)\n\nCalculate (1) the total land area of each drainage basin in the watershed and (2) the total area of underserved tracts within each drainage basin. Units are in feet for this projected coordinate system.\n\n# get only underserved tracts\ndattbunder <- dattbindex %>%\n  filter(underserved == \"Yes\")\n\n# total basin area\nbasinareas <- dattbdbasins %>%\n  mutate(area_ft = st_area(dattbdbasins)) %>%\n  group_by(WBID) %>%\n  summarise(db_area_ft = sum(area_ft))\n\n# underserved area within basins\nbasin_int <- st_intersection(basinareas, dattbunder)\n\nbasin_underareas <- basin_int %>%\n  mutate(area_int_ft = st_area(basin_int)) %>%\n  group_by(WBID) %>%\n  summarise(under_area_ft = sum(area_int_ft)) %>%\n  as.data.frame()\n\n# join area estimates\nareasjoined <- left_join(basinareas, basin_underareas, by = 'WBID') %>%\n  rowwise() %>%\n  select(matches('^WBID|^db|^under')) %>%\n  as.data.frame()\n\ndattbdbasins_under <- left_join(dattbdbasins, areasjoined, by = 'WBID')\n\nCalculate the proportion of each drainage basin containing underserved communities.\n\ndattbdbasins_under <- dattbdbasins_under %>%\n  mutate(under_area_ft = ifelse(is.na(under_area_ft), 0, under_area_ft)) %>%\n  mutate(pct_under = under_area_ft/db_area_ft * 100) %>%\n  mutate(pct_under = as.numeric(pct_under))\n\nCreate a map showing priority drainage basins based on the presence of underserved communities. Hover over the drainage basins to view the name of the water body assessment unit.\n\nmapviewOptions(\"basemaps.color.shuffle\" = FALSE)\n\nmapview(dattbdbasins_under, zcol = \"pct_under\", col.regions = brewer.pal(6, \"Reds\"), at = seq(0, 100, 20), layer.name = \"Underserved Tracts (% of DB)\", label = \"WATERBODY_NAME\")"
  },
  {
    "objectID": "overburdened.html",
    "href": "overburdened.html",
    "title": "Mapping underserved and overburdened communities",
    "section": "",
    "text": "Below, we have provided instructions for replicating our methodology for mapping underserved and overburdened communities in Tampa Bay. To view instructions for downloading the necessary source data, as well as an overview of the environmental justice metrics we consider, see Getting environmental justice data.\nLoad the required R packages (install first as needed).\n\nlibrary(sf)\nlibrary(mapview)\nlibrary(dplyr)\nlibrary(RColorBrewer)\nlibrary(leafsync)\n\nLoad the map of underserved communities in Tampa Bay made in the previous page. Map the number of burdens facing underserved communities across the watershed.\n\nload(file = 'data/dattbunderover.RData')\n\nmapview(dattbunderover, zcol = \"thresholdEJ_N\", col.regions = brewer.pal(8, \"YlOrRd\"), layer.name = \"No. of Burdens\")\n\n\n\n\n\n\nView the underserved tracts that also meet our definition of overburdened communities. The areas in red are those that rank in the 80th percentile (or greater) nationally in one or more of the environmental justice screening variables.\n\nmapview(dattbunderover, zcol = \"overburdened\", col.regions = list(\"gray\",\"red\"), layer.name = \"Overburdened\")\n\n\n\n\n\n\nYou can see that all but 3 underserved tracts in our watershed are also considered overburdened by one or more EJ issue. Run the code below to create a field listing the major EJ issues facing each community, which you can view in the map by hovering your cursor over a tract.\n\ndattbunderover <- dattbunderover %>%\n  mutate(CC = ifelse(thresholdEJ_agloss == 1 | thresholdEJ_floodr == 1, \"Climate Change\", NA),\n         NP = ifelse(thresholdEJ_greens == 1, \"Nature Deprevation\", NA),\n         AP = ifelse(thresholdEJ_pm2.5 == 1 | thresholdEJ_trafic == 1, \"Air Pollution\", NA),\n         WP = ifelse(thresholdEJ_wastew == 1, \"Water Pollution\", NA),\n         OP = ifelse(thresholdEJ_hwaste == 1 | thresholdEJ_ugtank == 1 | thresholdEJ_sfunds == 1 | thresholdEJ_bfield == 1 | thresholdEJ_phmine == 1, \"Other Pollution\", NA),\n         LE = ifelse(thresholdEJ_redlin == 1, \"Legacy Effects\", NA)) %>%\n  mutate(EJissues1 = paste(CC, NP, AP, WP, OP, LE, sep = \", \")) %>%\n  mutate(EJissues1 = gsub('NA, ', '', EJissues1)) %>%\n  mutate(EJissues1 = gsub(', NA', '', EJissues1))\n\nmapview(dattbunderover, zcol = \"thresholdEJ_N\", col.regions = brewer.pal(8, \"YlOrRd\"), label = \"EJissues1\", layer.name = \"No. of Burdens\")\n\n\n\n\n\n\nRun the code below to create another field listing the specific EJ issues facing each community. Hover over the tracts to see the changes.\n\ndattbunderover <- dattbunderover %>%\n  mutate(agloss = ifelse(thresholdEJ_agloss == 1, \"Agriculture loss\", NA),\n         floodr = ifelse(thresholdEJ_floodr == 1, \"Flood risk\", NA),\n         greens = ifelse(thresholdEJ_greens == 1, \"Lack of green space\", NA),\n         pm2.5 = ifelse(thresholdEJ_pm2.5 == 1, \"PM2.5\", NA),\n         trafic = ifelse(thresholdEJ_trafic == 1, \"Traffic volume\", NA),\n         wastew = ifelse(thresholdEJ_wastew == 1, \"Wastewater discharge\", NA),\n         hwaste = ifelse(thresholdEJ_hwaste == 1, \"Hazardous waste facilities\", NA),\n         ugtank = ifelse(thresholdEJ_ugtank == 1, \"Underground storage tanks\", NA),\n         sfunds = ifelse(thresholdEJ_sfunds == 1, \"Superfund sites\", NA),\n         bfield = ifelse(thresholdEJ_bfield == 1, \"Brownfield sites\", NA),\n         phmine = ifelse(thresholdEJ_phmine == 1, \"Phosphate mining\", NA),\n         redlin = ifelse(thresholdEJ_redlin == 1, \"Historic redlining\", NA)) %>%\n  mutate(EJissues1.1 = paste(agloss, floodr, greens, pm2.5, trafic, wastew, hwaste, ugtank, sfunds, bfield, phmine, redlin, sep = \", \")) %>%\n  mutate(EJissues1.1 = gsub('NA, ', '', EJissues1.1)) %>%\n  mutate(EJissues1.1 = gsub(', NA', '', EJissues1.1))\n\nmapview(dattbunderover, zcol = \"thresholdEJ_N\", col.regions = brewer.pal(8, \"YlOrRd\"), label = \"EJissues1.1\", layer.name = \"No. of Burdens\")\n\n\n\n\n\n\nYou can also use this data to compare underserved communities facing different EJ challenges. The code below allows you to compare locations of communities with 4 different burdens at once.\n\nmap_flood <- dattbunderover %>%\n  filter(thresholdEJ_floodr == 1) %>%\n  mapview(zcol = \"floodr\", col.regions = \"blue\", layer.name = \"Burden\")\n\nmap_wastew <- dattbunderover %>%\n  filter(thresholdEJ_wastew == 1) %>%\n  mapview(zcol = \"wastew\", col.regions = \"black\", layer.name = \"Burden\")\n\nmap_greens <- dattbunderover %>%\n  filter(thresholdEJ_greens == 1) %>%\n  mapview(zcol = \"greens\", col.regions = \"green\", layer.name = \"Burden\")\n\nmap_bfield <- dattbunderover %>%\n  filter(thresholdEJ_bfield == 1) %>%\n  mapview(zcol = \"bfield\", col.regions = \"brown\", layer.name = \"Burden\")\n\nsync(map_flood, map_wastew, map_greens, map_bfield)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe have saved this final layer as an RData object for internal and external use. This will serve as the primary data guiding our Equity Strategy, and external parties are free to download this data for their own use.\n\n# save the layer as an RData object\ndattbequity <- dattbunderover %>%\n  rowwise() %>%\n  select(matches('^threshold|^ID|^under|^over|^EJissues'))\n\n\nsave(dattbunderover, file = 'data/dattbequity.RData')"
  }
]